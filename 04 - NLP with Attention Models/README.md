C2 - Natural Language Processing with Sequence Models

### Week 1

**Assignment**
- NMT with Attention ([*C4_W1_Assignment.ipynb*]())

**Ungraded Labs**
- Basic Attention ([*C4_W1_Ungraded_Lab_1_Basic_Attention.ipynb*]())
- Scaled Dot-Product Attention ([*C4_W1_Ungraded_Lab_2_QKV_Attention.ipynb*]())
- BLEU Score ([*C4_W1_Ungraded_Lab_3_Bleu_Score.ipynb*]())
- Stack Semantics ([*C4_W1_Ungraded_Lab_4_Stack_Semantics.ipynb*]())

### Week 2

**Assignment**
- Transformer Summarizer ([*C4_W2_Assignment.ipiynb*]())

**Ungraded Labs**
- Attention ([*C4_W2_Ungraded_Lab_1_Attention.ipynb*]())
- The Transformer Decoder ([*C4_W2_Ungraded_Lab_2_Transformer_Decoder.ipynb*]())

### Week 3

**Assignment**
- Question Answering ([*C4_W3_Assignment.ipynb*]())

**Ungraded Labs**
- SentencePiece and BPE ([*C4_W3_SentencePiece_and_BPE.ipynb*]())

### Week 4

**Assignment**
- Chatbot ([*C4_W4_Assignment.ipynb*]())

**Ungraded Labs**
- Reformer LSH ([*C4_W4_Ungraded_Lab_1_Reformer_LSH.ipynb*]())
- Revnet ([*C4_W4_Ungraded_Lab_2_Revnet.ipynb*]())
