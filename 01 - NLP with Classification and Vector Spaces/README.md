## C1 - Natural Language Processing with Classification and Vector Spaces

### Week 1

**Assignment**
- Logistic Regression ([*C1_W1_Assignment.ipynb*]())

**Ungraded Labs**
- Natural Language Preprocessing ([*C1_W1_lecture_nb_01_preprocessing.ipynb*]())
- Visualizing Word Frequencies ([*C1_W1_lecture_nb_02_word frequencies.ipynb*]())
- Visualizing tweets and Logistic Regression models ([*C1_W1_lecture_nb_03_logistic_regression_model.ipynb*]())

### Week 2

**Assignment**
- Naive Bayes ([*C1_W2_Assignment.ipynb*]())

**Ungraded Labs**
- Visualizing likelihoods and confidence ellipses ([*C1_W2_lecture_nb_01_visualizing_naive_bayes.ipynb*]())

### Week 3

**Assignment**
- Assignment: Vector Space Models ([*C1_W3_Assignment.ipynb*]())

**Ungraded Labs**
- Linear algebra in Python with Numpy ([*C1_W3_lecture_nb_01_linear_algebra.ipynb*]())
- Manipulating word embeddings ([*C1_W3_lecture_nb_02_manipulating_word_embeddings.ipynb*]())
- Another explanation about PCA ([*C1_W3_lecture_nb_03_pca.ipynb*]())

### Week 4

**Assignment**
- Word Translation ([*C1_W4_Assignment.ipynb*]())

**Ungraded Labs**
- Rotation matrices in R2 ([*C1_W4_lecture_nb_01_vector_manipulation.ipynb*]())
- Hash tables ([*C1_W4_lecture_nb_02_hash_functions_and_multiplanes*]())